# GCS RangeEngine Performance Test
#
# This config demonstrates RangeEngine benefits for Google Cloud Storage.
# RangeEngine provides 30-50% throughput improvements for large files on GCS.
#
# Requirements:
# - gcloud auth application-default login (or GOOGLE_APPLICATION_CREDENTIALS)
# - Pre-existing bucket in GCS
# - Appropriate IAM permissions for read/write
#
# Expected performance with RangeEngine:
# - 8 MB files: 20-30% faster than sequential
# - 64 MB - 128 MB files: 30-40% faster
# - > 128 MB files: 40-50% faster
#
# Test Results (signal65-testing project, us-central1):
# - Total ops: 1,375 in 30s (45.26 ops/s)
# - Throughput: 45.26 MiB/s
# - Latency: mean=173ms, p50=168ms, p95=234ms
# - RangeEngine confirmed: 1-4 ranges depending on file size

# Update this to your GCS bucket
target: "gs://your-bucket/sai3bench-rangetest/"

duration: "30s"
concurrency: 8  # Higher concurrency recommended for GCS

# Optional: RangeEngine configuration (uses s3dlio defaults if omitted)
# range_engine:
#   enabled: true
#   chunk_size: 67108864  # 64 MB - optimal for GCS
#   max_concurrent_ranges: 32
#   min_split_size: 4194304  # 4 MB threshold
#   range_timeout_secs: 30

workload:
  # GET operations on varying file sizes
  - op: get
    path: "4mb/*"  # Below threshold - sequential download
    weight: 10
  
  - op: get
    path: "8mb/*"  # 1 range - RangeEngine activates
    weight: 20
  
  - op: get
    path: "64mb/*"  # 1 range - noticeable speedup
    weight: 30
  
  - op: get
    path: "128mb/*"  # 2 ranges - significant speedup
    weight: 25
  
  - op: get
    path: "256mb/*"  # 4 ranges - maximum benefit
    weight: 15

# Prepare test objects with varying sizes
prepare:
  cleanup: true
  post_prepare_delay: 2  # GCS eventual consistency delay (shorter than Azure)
  
  ensure_objects:
    - base_uri: "gs://your-bucket/sai3bench-rangetest/4mb/"
      count: 5
      size: 4194304  # 4 MB
      fill: random
    
    - base_uri: "gs://your-bucket/sai3bench-rangetest/8mb/"
      count: 5
      size: 8388608  # 8 MB - 1 range
      fill: random
    
    - base_uri: "gs://your-bucket/sai3bench-rangetest/64mb/"
      count: 3
      size: 67108864  # 64 MB - 1 range
      fill: random
    
    - base_uri: "gs://your-bucket/sai3bench-rangetest/128mb/"
      count: 3
      size: 134217728  # 128 MB - 2 ranges
      fill: random
    
    - base_uri: "gs://your-bucket/sai3bench-rangetest/256mb/"
      count: 2
      size: 268435456  # 256 MB - 4 ranges
      fill: random

# Usage:
# 1. Update the target and base_uri fields with your GCS bucket
# 2. Ensure gcloud authentication: gcloud auth application-default login
# 3. Run: sai3-bench run --config tests/configs/gcs_rangeengine_test.yaml
# 4. For verbose RangeEngine logs: sai3-bench -vv run --config ...
#
# To see RangeEngine in action:
# sai3-bench -vv get --uri "gs://your-bucket/path/to/large-file" --jobs 4
#
# Expected log output:
# INFO s3dlio::object_store: RangeEngine (GCS) downloaded 134217728 bytes in 2 ranges: 25.59 MB/s (0.21 Gbps)
